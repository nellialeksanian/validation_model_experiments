{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16xDGrnTooyy",
        "outputId": "60637914-3603-4934-8cee-0df637859e38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "6BeIfzaKXyn4"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import ast\n",
        "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
        "import torch\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VC_1jsxQXM-d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ed51abf-ffe4-4e68-f9e5-e3e86769d63a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "splits = {'train': 'data/train-00000-of-00001.parquet', 'test': 'data/test-00000-of-00001.parquet'}\n",
        "big_df = pd.read_parquet(\"hf://datasets/wandb/RAGTruth-processed/\" + splits[\"test\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Q6XcsfpX8MH"
      },
      "outputs": [],
      "source": [
        "big_df = big_df[big_df['quality'] == 'good']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_AOml56GYEfR"
      },
      "outputs": [],
      "source": [
        "def extract_binary_label(hallucination_labels):\n",
        "    return 1 if any(value == 1 for value in hallucination_labels.values()) else 0\n",
        "big_df['binary_label'] = big_df['hallucination_labels_processed'].apply(extract_binary_label)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summary_df = big_df[big_df['task_type'] == 'Summary']\n",
        "\n",
        "true_examples = summary_df[summary_df['binary_label'] == True].sample(n=50, random_state=42)\n",
        "false_examples = summary_df[summary_df['binary_label'] == False].sample(n=50, random_state=42)\n",
        "\n",
        "balanced_df = pd.concat([true_examples, false_examples]).sample(frac=1, random_state=42)\n",
        "\n",
        "balanced_df.to_csv(\"balanced_summary_dataset.csv\", index=False)"
      ],
      "metadata": {
        "id": "YN8arvBaHTVl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "small_df = pd.read_json(\"hf://datasets/aporia-ai/rag_hallucinations/rag_hallucinations_dataset.json\")\n",
        "small_df['binary_label'] = small_df['is_hallucination'].map({True: 1, False: 0})\n",
        "small_df.rename(columns={\"question\": \"query\", \"answer\": \"output\"}, inplace=True)"
      ],
      "metadata": {
        "id": "6osdKT5ZHqBS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "small_df = small_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "false_samples = small_df[small_df[\"binary_label\"] == 0].head(100)\n",
        "true_samples = small_df[small_df[\"binary_label\"] == 1].head(100)\n",
        "\n",
        "balanced_small_test = pd.concat([false_samples, true_samples]).sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "balanced_small_test.to_csv(\"/content/balanced_small_test.csv\")"
      ],
      "metadata": {
        "id": "EmfW7hdjH-t0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "cfiuhfCu2fJ6"
      },
      "outputs": [],
      "source": [
        "small_balanced_df = pd.read_csv(\"/content/balanced_small_test.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summary_dataset = pd.read_csv(\"/content/balanced_summary_dataset.csv\")"
      ],
      "metadata": {
        "id": "KMw44EDr3Ku4"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "2fjvJwVGYXXV"
      },
      "outputs": [],
      "source": [
        "def tokenize_function(row, tokenizer, max_length=512):\n",
        "    query_max_len = max_length // 4\n",
        "    context_max_len = max_length // 2\n",
        "    output_max_len = max_length // 4\n",
        "\n",
        "    query_text = f\"QUERY: {row['query']} \"\n",
        "    context_text = f\"CONTEXT: {row['context']} \"\n",
        "    output_text = f\"OUTPUT: {row['output']} \"\n",
        "\n",
        "    query_tokens = tokenizer(query_text, truncation=True, padding='max_length', max_length=query_max_len, return_tensors=\"pt\")\n",
        "    context_tokens = tokenizer(context_text, truncation=True, padding='max_length', max_length=context_max_len, return_tensors=\"pt\")\n",
        "    output_tokens = tokenizer(output_text, truncation=True, padding='max_length', max_length=output_max_len, return_tensors=\"pt\")\n",
        "\n",
        "    combined_input_ids = torch.cat([\n",
        "        query_tokens['input_ids'][0],\n",
        "        context_tokens['input_ids'][0],\n",
        "        output_tokens['input_ids'][0]\n",
        "    ]).unsqueeze(0)\n",
        "\n",
        "    combined_attention_mask = torch.cat([\n",
        "        query_tokens['attention_mask'][0],\n",
        "        context_tokens['attention_mask'][0],\n",
        "        output_tokens['attention_mask'][0]\n",
        "    ]).unsqueeze(0)\n",
        "\n",
        "    return {\"input_ids\": combined_input_ids, \"attention_mask\": combined_attention_mask}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "vJAdz00YYQU5"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer, max_length=512):\n",
        "        self.data = data\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.data.iloc[idx]\n",
        "        tokens = tokenize_function(row, self.tokenizer, self.max_length)\n",
        "        labels = {\n",
        "            \"binary_label\": torch.tensor(row['binary_label'], dtype=torch.float),\n",
        "        }\n",
        "        return {**tokens, **labels}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "itJo-RbLYRJ-"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "import torch\n",
        "\n",
        "def collate_fn(batch):\n",
        "\n",
        "    model_name = \"microsoft/deberta-v3-base\"\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=False)\n",
        "\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "    binary_labels = []\n",
        "\n",
        "    # Iterate over the examples in the batch and prepare the data\n",
        "    for example in batch:\n",
        "        # Ensure each sequence has the correct shape (1D tensor)\n",
        "        input_ids.append(example['input_ids'].squeeze(0))  # Remove the batch dimension\n",
        "        attention_masks.append(example['attention_mask'].squeeze(0))\n",
        "        binary_labels.append(example['binary_label'])\n",
        "\n",
        "\n",
        "    input_ids = torch.nn.utils.rnn.pad_sequence(input_ids, batch_first=True, padding_value=tokenizer.pad_token_id)\n",
        "    attention_masks = torch.nn.utils.rnn.pad_sequence(attention_masks, batch_first=True, padding_value=0)\n",
        "\n",
        "    return {\n",
        "        'input_ids': input_ids,\n",
        "        'attention_mask': attention_masks,\n",
        "        'binary_label':  torch.tensor(binary_labels, dtype=torch.float)\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "lgQ8dgioubAu"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from tqdm import tqdm\n",
        "\n",
        "def test_model(model, test_dataset, tokenizer, batch_size, device):\n",
        "    test_dataloader = DataLoader(test_dataset, batch_size=batch_size, collate_fn=collate_fn)\n",
        "\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    all_labels = []\n",
        "    all_predictions = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(test_dataloader, desc=\"Evaluating\"):\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['binary_label'].to(device).long()\n",
        "\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "            logits = outputs.logits\n",
        "\n",
        "            probabilities = torch.sigmoid(logits)\n",
        "            predictions = (probabilities >= 0.5).long()\n",
        "\n",
        "            all_predictions.extend(predictions.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    report = classification_report(all_labels, all_predictions, target_names=[\"Class 0\", \"Class 1\"], zero_division=1)\n",
        "    accuracy = accuracy_score(all_labels, all_predictions)\n",
        "\n",
        "    print(\"Classification Report:\")\n",
        "    print(report)\n",
        "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "    return report, accuracy\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yK4-NNmhY_-P"
      },
      "source": [
        "### Testing bert-base"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "model_name = \"bert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model_bin = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=1)\n",
        "model_bin.load_state_dict(torch.load(\"/content/drive/MyDrive/hallucinations/model_bert_5_epochs.pth\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nOM-ClDufgiA",
        "outputId": "a6ce34f4-f023-49e9-a0ea-5ea70b73b0ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "def56AL54Nlo"
      },
      "outputs": [],
      "source": [
        "balanced_small_dataset = CustomDataset(small_balanced_df, tokenizer, max_length = 512)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summary_test_dataset = CustomDataset(summary_dataset, tokenizer, max_length = 512)"
      ],
      "metadata": {
        "id": "VmhIvqC_3iqg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "batch_size = 32\n",
        "test_model(model_bin, balanced_small_dataset, tokenizer, batch_size, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kNhm9Gfzfxhw",
        "outputId": "cd2e64f7-a26e-49c2-c5f4-01e40de00373"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 7/7 [00:09<00:00,  1.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Class 0       0.60      0.94      0.73       100\n",
            "     Class 1       0.86      0.37      0.52       100\n",
            "\n",
            "    accuracy                           0.66       200\n",
            "   macro avg       0.73      0.66      0.62       200\n",
            "weighted avg       0.73      0.66      0.62       200\n",
            "\n",
            "Accuracy: 65.50%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('              precision    recall  f1-score   support\\n\\n     Class 0       0.60      0.94      0.73       100\\n     Class 1       0.86      0.37      0.52       100\\n\\n    accuracy                           0.66       200\\n   macro avg       0.73      0.66      0.62       200\\nweighted avg       0.73      0.66      0.62       200\\n',\n",
              " 0.655)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "batch_size = 32\n",
        "test_model(model_bin, summary_test_dataset, tokenizer, batch_size, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JuftAvOEhZWU",
        "outputId": "5d7dc3a2-679a-480d-e8f4-76c5555fe687"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 4/4 [00:04<00:00,  1.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Class 0       0.56      0.82      0.67        50\n",
            "     Class 1       0.67      0.36      0.47        50\n",
            "\n",
            "    accuracy                           0.59       100\n",
            "   macro avg       0.61      0.59      0.57       100\n",
            "weighted avg       0.61      0.59      0.57       100\n",
            "\n",
            "Accuracy: 59.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('              precision    recall  f1-score   support\\n\\n     Class 0       0.56      0.82      0.67        50\\n     Class 1       0.67      0.36      0.47        50\\n\\n    accuracy                           0.59       100\\n   macro avg       0.61      0.59      0.57       100\\nweighted avg       0.61      0.59      0.57       100\\n',\n",
              " 0.59)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMqikI4kwUtx"
      },
      "source": [
        "### testing roberta-base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281,
          "referenced_widgets": [
            "5edbc414593941da8e20e00c57efa4de",
            "dc0f94e56a7c4b9ca0c18729112f508d",
            "ec1276f4dc59416f8cef4533b6e444fb",
            "cb5946f0999a45fa97e625dab5b463e4",
            "d181d77d78e4442d93a8bb1c5c6c062b",
            "14dacd265adb4ac0aedc1e29a6893dda",
            "8cc7ee23731342b4b27ef59e415fb662",
            "14222ecb89354b6596bf6c7bb7918477",
            "748def1a40e74420bde6edcac80888bb",
            "7666e6991a9e4b9aa187fd2c1649ba68",
            "be0b7af4aa9d4098ab568df8b61c94da",
            "6f77b66ee0a84fe7a8cbbea6590d9880",
            "9939fe6b316042e3851d32311ed8122e",
            "34dfdbe7cdb6402991f858bf3f8f52c1",
            "adc8470885ca4f32b7e32259406eb187",
            "9a6ba8ddcbea48e9a8e4fb30afd67b42",
            "1f2a23847d7d45bcbf9d10b338d0cf69",
            "7dfe062936f345e7b8518d924b06890f",
            "e7b65708c0064412a2400e09a5aaad50",
            "b10410e4f89a4fc3a5ac5578cff6082c",
            "4495f76069a84ef0a13d3eff89691c9f",
            "db7ffb53f3e84e78bc4f12baedadf149",
            "e532f246a69c49339bfa9e053e324ef8",
            "6deff0950c1c4a8eae156d7ce9dd81cf",
            "6888a34020a8462493a96c9020d1e2f0",
            "82e0896dffb14239ad473157d5478c8b",
            "fa2959e6e4ee48ed94e38420d4848c83",
            "158a9d165e02459fa5d13a41dce38437",
            "fe9622e0ec334b50a7a20bfeb1764466",
            "390aa648c6c34b178737cef311ba4d5c",
            "44ced63851224da2afa6333265d17b0d",
            "df69cbadb1594a068f1c98cbdab9df43",
            "40ce1e4c6f964a8988c1dbc46d9ac461",
            "98b6fd7427eb4b88b165d773d68651b7",
            "4f405146c86b4642a5ba46c27884b084",
            "589f83b4ad7c467b9af2d496137218ea",
            "8a0602d129994f4bb66c3a9407b52aae",
            "9e1b6d7ad04a43ae933485c95e1fe016",
            "a82b3d6d83df41b2aa46f050b40ce6b5",
            "078e8b26e03849dc83851fee1e7bd4f6",
            "3e5eeb7ce7c148d4a9d69eeb785af662",
            "3e919e9d121b43b2aa53669c37bfd643",
            "ecf48d5a7fce4f7b9615024c0f88e80e",
            "e7ce6f0af8a8488ca95baca1cf3ac484",
            "1f904517357b440abf1e9422806894f3",
            "cee0a58587b74d298bf78e4823485d2f",
            "944ad2aa55dc4a39b128ec391a824b23",
            "612a50ef93af414a96de4d59058e569c",
            "fbe64c5daf53490fb2b380e25d4f4fee",
            "bfffece6cb204f9ab72ce50dc23e21f3",
            "ac74ea3b614b423b861ce93d4b8b3b3f",
            "8950084e047d4bce805cb4c575ddd82c",
            "e68163f0e5904235b9059b47acac6e34",
            "9fe5163b8aa84b5cbd7b139f97346567",
            "b970900d4d564d94b6f6aeed48230bfa",
            "7add994ddc5b4b8f919929db8e670a03",
            "6eaf3f62e14e463e8c0fe70ca9df2e44",
            "266f6bd747384ac492be71fd942a5ebd",
            "c74a317f420048548ec898347f6a3441",
            "f24f0e135dac4f50bd84dea209f4531e",
            "6f1823c6dc2d42659ae576619e11284f",
            "80cac515949a4c2fa3a9d5c5215cf2af",
            "5ec1130b35304b4491d89670d32432c6",
            "5013d17eb983462f82c8d3b0c2b49f14",
            "8f5d0b43ef004ea6a42d5f70d32691fe",
            "8d5c9400fd99402b9610e7e99c242410"
          ]
        },
        "id": "_EzF7XcowXNX",
        "outputId": "932aa4d1-c2e8-4a38-8904-be901e1f20e8"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5edbc414593941da8e20e00c57efa4de"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6f77b66ee0a84fe7a8cbbea6590d9880"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e532f246a69c49339bfa9e053e324ef8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "98b6fd7427eb4b88b165d773d68651b7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1f904517357b440abf1e9422806894f3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7add994ddc5b4b8f919929db8e670a03"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "model_name = \"roberta-base\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=1)\n",
        "model.load_state_dict(torch.load(\"/content/drive/MyDrive/hallucinations/model_roberta_5_epochs.pth\",  map_location=torch.device('cpu')))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "96iXY6Hw4jby"
      },
      "outputs": [],
      "source": [
        "balanced_small_dataset = CustomDataset(small_balanced_df, tokenizer, max_length = 512)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summary_test_dataset = CustomDataset(summary_dataset, tokenizer, max_length = 512)"
      ],
      "metadata": {
        "id": "pm6ZUc0x376s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "flQiPAW34qs7",
        "outputId": "6d89a71b-5cea-4ed5-9ece-3ccde0aec1bf"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 7/7 [00:07<00:00,  1.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Class 0       0.96      0.92      0.94       100\n",
            "     Class 1       0.92      0.96      0.94       100\n",
            "\n",
            "    accuracy                           0.94       200\n",
            "   macro avg       0.94      0.94      0.94       200\n",
            "weighted avg       0.94      0.94      0.94       200\n",
            "\n",
            "Accuracy: 94.00%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "('              precision    recall  f1-score   support\\n\\n     Class 0       0.96      0.92      0.94       100\\n     Class 1       0.92      0.96      0.94       100\\n\\n    accuracy                           0.94       200\\n   macro avg       0.94      0.94      0.94       200\\nweighted avg       0.94      0.94      0.94       200\\n',\n",
              " 0.94)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "batch_size = 32\n",
        "test_model(model, balanced_small_dataset, tokenizer, batch_size, device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "batch_size = 32\n",
        "test_model(model, summary_test_dataset, tokenizer, batch_size, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8h38o72A4Ebj",
        "outputId": "7de79bc6-6eab-4a4f-aa53-176aff5a6e51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 4/4 [00:03<00:00,  1.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Class 0       0.60      0.68      0.64        50\n",
            "     Class 1       0.63      0.54      0.58        50\n",
            "\n",
            "    accuracy                           0.61       100\n",
            "   macro avg       0.61      0.61      0.61       100\n",
            "weighted avg       0.61      0.61      0.61       100\n",
            "\n",
            "Accuracy: 61.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('              precision    recall  f1-score   support\\n\\n     Class 0       0.60      0.68      0.64        50\\n     Class 1       0.63      0.54      0.58        50\\n\\n    accuracy                           0.61       100\\n   macro avg       0.61      0.61      0.61       100\\nweighted avg       0.61      0.61      0.61       100\\n',\n",
              " 0.61)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing DEBERTA"
      ],
      "metadata": {
        "id": "cQT62FzO5bAp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import torch\n",
        "\n",
        "model_name = \"microsoft/deberta-v3-base\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=False)\n",
        "model_bin = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=1)\n",
        "model_bin.load_state_dict(torch.load(\"/content/drive/MyDrive/hallucinations/model_deberta_5_epochs.pth\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eOJsJ9BR5a2y",
        "outputId": "5698fc79-a76c-4aa8-d429-caf944a4af08"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "balanced_small_dataset = CustomDataset(small_balanced_df, tokenizer, max_length = 512)"
      ],
      "metadata": {
        "id": "_sFnpjc86jbi"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "batch_size = 32\n",
        "test_model(model_bin, balanced_small_dataset, tokenizer, batch_size, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GG2zRJHFclHk",
        "outputId": "7bfe0cf9-1438-41f2-c2e7-d355c2fefcb5"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 7/7 [00:13<00:00,  1.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Class 0       0.80      0.79      0.79       100\n",
            "     Class 1       0.79      0.80      0.80       100\n",
            "\n",
            "    accuracy                           0.80       200\n",
            "   macro avg       0.80      0.80      0.79       200\n",
            "weighted avg       0.80      0.80      0.79       200\n",
            "\n",
            "Accuracy: 79.50%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('              precision    recall  f1-score   support\\n\\n     Class 0       0.80      0.79      0.79       100\\n     Class 1       0.79      0.80      0.80       100\\n\\n    accuracy                           0.80       200\\n   macro avg       0.80      0.80      0.79       200\\nweighted avg       0.80      0.80      0.79       200\\n',\n",
              " 0.795)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summary_test_dataset = CustomDataset(summary_dataset, tokenizer, max_length = 512)"
      ],
      "metadata": {
        "id": "5ZtTRLlB6tkW"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "batch_size = 32\n",
        "test_model(model_bin, summary_test_dataset, tokenizer, batch_size, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zws9fBMOdniw",
        "outputId": "575699e9-3474-4e79-e934-ff590b9f70c0"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 4/4 [00:08<00:00,  2.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Class 0       0.54      0.74      0.62        50\n",
            "     Class 1       0.58      0.36      0.44        50\n",
            "\n",
            "    accuracy                           0.55       100\n",
            "   macro avg       0.56      0.55      0.53       100\n",
            "weighted avg       0.56      0.55      0.53       100\n",
            "\n",
            "Accuracy: 55.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('              precision    recall  f1-score   support\\n\\n     Class 0       0.54      0.74      0.62        50\\n     Class 1       0.58      0.36      0.44        50\\n\\n    accuracy                           0.55       100\\n   macro avg       0.56      0.55      0.53       100\\nweighted avg       0.56      0.55      0.53       100\\n',\n",
              " 0.55)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing lightning roberta"
      ],
      "metadata": {
        "id": "zjkoDCagXqHC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pytorch_lightning"
      ],
      "metadata": {
        "id": "fOKfmkI8XzdF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import pytorch_lightning as pl\n",
        "\n",
        "class BinaryClassifierPL(pl.LightningModule):\n",
        "    def __init__(self, model, lr=2e-5):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters()\n",
        "        self.model = model\n",
        "        self.lr = lr\n",
        "        self.criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        return self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        input_ids = batch['input_ids']\n",
        "        attention_mask = batch['attention_mask']\n",
        "        labels = batch['binary_label'].long()\n",
        "\n",
        "        outputs = self(input_ids, attention_mask)\n",
        "        logits = outputs.logits\n",
        "        loss = self.criterion(logits, labels)\n",
        "\n",
        "        self.log(\"train_loss\", loss, prog_bar=True)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        input_ids = batch['input_ids']\n",
        "        attention_mask = batch['attention_mask']\n",
        "        labels = batch['binary_label'].long()\n",
        "\n",
        "        outputs = self(input_ids, attention_mask)\n",
        "        logits = outputs.logits\n",
        "        loss = self.criterion(logits, labels)\n",
        "\n",
        "        preds = torch.argmax(logits, dim=1)\n",
        "        acc = (preds == labels).float().mean()\n",
        "\n",
        "        # Log loss and accuracy averaged across the epoch\n",
        "        self.log(\"val_loss\", loss, prog_bar=True, on_epoch=True, on_step=False)\n",
        "        self.log(\"val_acc\", acc, prog_bar=True, on_epoch=True, on_step=False)\n",
        "\n",
        "        return {\"val_loss\": loss, \"val_acc\": acc}\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return torch.optim.AdamW(self.parameters(), lr=self.lr)"
      ],
      "metadata": {
        "id": "FQxT1JxAXtsp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import RobertaForSequenceClassification\n",
        "import torch\n",
        "\n",
        "model_name = \"roberta-base\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "state_dict = torch.load(\"/content/drive/MyDrive/hallucinations/lightning/model_roberta_5_epochs.pth\")\n",
        "\n",
        "# Filter out keys for just the roberta model\n",
        "new_state_dict = {k.replace(\"model.model.\", \"\"): v for k, v in state_dict.items() if k.startswith(\"model.model.\")}\n",
        "\n",
        "roberta = RobertaForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
        "roberta.load_state_dict(new_state_dict)\n",
        "\n",
        "lightning_model = BinaryClassifierPL(roberta)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52vANJPGYQPC",
        "outputId": "730a4d19-6e08-4fdc-8413-2d52583d75a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "\n",
        "def test_model(model, test_dataset, tokenizer, batch_size, device, collate_fn):\n",
        "    # Create DataLoader for the test dataset\n",
        "    test_dataloader = DataLoader(test_dataset, batch_size=batch_size, collate_fn=collate_fn)\n",
        "\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    all_labels = []\n",
        "    all_predictions = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(test_dataloader, desc=\"Evaluating\"):\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['binary_label'].to(device).long()\n",
        "\n",
        "            # Forward pass using model's defined forward()\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "            logits = outputs.logits if hasattr(outputs, 'logits') else outputs  # handle LightningModule\n",
        "\n",
        "            probabilities = torch.softmax(logits, dim=1)[:, 1]  # Get probs for class 1\n",
        "            predictions = (probabilities >= 0.5).long()\n",
        "\n",
        "            all_predictions.extend(predictions.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    report = classification_report(all_labels, all_predictions, target_names=[\"Class 0\", \"Class 1\"], zero_division=1)\n",
        "    accuracy = accuracy_score(all_labels, all_predictions)\n",
        "\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(report)\n",
        "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "    return report, accuracy\n"
      ],
      "metadata": {
        "id": "gkOU4eCmYZ6g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "balanced_small_dataset = CustomDataset(small_balanced_df, tokenizer, max_length = 512)"
      ],
      "metadata": {
        "id": "mhmCZqCsZd0o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary_dataset_test = CustomDataset(summary_dataset, tokenizer, max_length = 512)"
      ],
      "metadata": {
        "id": "Jy5tAPw2aQ12"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_model(lightning_model, balanced_small_dataset, tokenizer, 16, \"cuda\", collate_fn=collate_fn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4SL-K1l_ZjqC",
        "outputId": "dcd47bc6-5dc4-41ce-8fcd-dbdb72c543c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 13/13 [00:10<00:00,  1.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Class 0       0.90      0.90      0.90       100\n",
            "     Class 1       0.90      0.90      0.90       100\n",
            "\n",
            "    accuracy                           0.90       200\n",
            "   macro avg       0.90      0.90      0.90       200\n",
            "weighted avg       0.90      0.90      0.90       200\n",
            "\n",
            "Accuracy: 90.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('              precision    recall  f1-score   support\\n\\n     Class 0       0.90      0.90      0.90       100\\n     Class 1       0.90      0.90      0.90       100\\n\\n    accuracy                           0.90       200\\n   macro avg       0.90      0.90      0.90       200\\nweighted avg       0.90      0.90      0.90       200\\n',\n",
              " 0.9)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_model(lightning_model, summary_dataset_test, tokenizer, 16, \"cuda\", collate_fn=collate_fn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qiHfD6eqaNgW",
        "outputId": "5361ffc4-f45c-48ad-9ea8-55092bb2c2f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 7/7 [00:08<00:00,  1.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Class 0       0.57      0.88      0.69        50\n",
            "     Class 1       0.74      0.34      0.47        50\n",
            "\n",
            "    accuracy                           0.61       100\n",
            "   macro avg       0.66      0.61      0.58       100\n",
            "weighted avg       0.66      0.61      0.58       100\n",
            "\n",
            "Accuracy: 61.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('              precision    recall  f1-score   support\\n\\n     Class 0       0.57      0.88      0.69        50\\n     Class 1       0.74      0.34      0.47        50\\n\\n    accuracy                           0.61       100\\n   macro avg       0.66      0.61      0.58       100\\nweighted avg       0.66      0.61      0.58       100\\n',\n",
              " 0.61)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "collapsed_sections": [
        "zjkoDCagXqHC"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}